{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "933a6628-f986-448d-9f8a-febc89dcce83",
   "metadata": {},
   "source": [
    "# Venn multicalibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eaf052e9-1b03-429a-9fa9-bb3b5e4e423d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_original</th>\n",
       "      <th>pred_calibrated</th>\n",
       "      <th>pred_lower</th>\n",
       "      <th>pred_upper</th>\n",
       "      <th>pred_oracle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.617116</td>\n",
       "      <td>-0.725925</td>\n",
       "      <td>-0.715319</td>\n",
       "      <td>6.488018</td>\n",
       "      <td>-0.700708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.707054</td>\n",
       "      <td>10.378927</td>\n",
       "      <td>10.227502</td>\n",
       "      <td>17.420197</td>\n",
       "      <td>10.227502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.873842</td>\n",
       "      <td>-6.000531</td>\n",
       "      <td>-5.976511</td>\n",
       "      <td>-4.003037</td>\n",
       "      <td>-5.972508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.243047</td>\n",
       "      <td>3.753304</td>\n",
       "      <td>3.713832</td>\n",
       "      <td>8.898633</td>\n",
       "      <td>3.819000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.239594</td>\n",
       "      <td>0.104059</td>\n",
       "      <td>0.103734</td>\n",
       "      <td>1.640053</td>\n",
       "      <td>0.103734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3127</th>\n",
       "      <td>0.000023</td>\n",
       "      <td>-1.098926</td>\n",
       "      <td>-1.090276</td>\n",
       "      <td>2.790084</td>\n",
       "      <td>-1.050922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3128</th>\n",
       "      <td>2.592913</td>\n",
       "      <td>-0.192757</td>\n",
       "      <td>-0.191530</td>\n",
       "      <td>2.945793</td>\n",
       "      <td>-0.178803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3129</th>\n",
       "      <td>1.883390</td>\n",
       "      <td>-4.357733</td>\n",
       "      <td>-4.314327</td>\n",
       "      <td>0.596205</td>\n",
       "      <td>-4.254564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3130</th>\n",
       "      <td>13.608382</td>\n",
       "      <td>8.011550</td>\n",
       "      <td>7.962045</td>\n",
       "      <td>11.008430</td>\n",
       "      <td>7.999120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>14.555404</td>\n",
       "      <td>11.843287</td>\n",
       "      <td>11.650528</td>\n",
       "      <td>19.674500</td>\n",
       "      <td>11.992319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3132 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pred_original  pred_calibrated  pred_lower  pred_upper  pred_oracle\n",
       "0          1.617116        -0.725925   -0.715319    6.488018    -0.700708\n",
       "1          3.707054        10.378927   10.227502   17.420197    10.227502\n",
       "2          1.873842        -6.000531   -5.976511   -4.003037    -5.972508\n",
       "3          7.243047         3.753304    3.713832    8.898633     3.819000\n",
       "4          2.239594         0.104059    0.103734    1.640053     0.103734\n",
       "...             ...              ...         ...         ...          ...\n",
       "3127       0.000023        -1.098926   -1.090276    2.790084    -1.050922\n",
       "3128       2.592913        -0.192757   -0.191530    2.945793    -0.178803\n",
       "3129       1.883390        -4.357733   -4.314327    0.596205    -4.254564\n",
       "3130      13.608382         8.011550    7.962045   11.008430     7.999120\n",
       "3131      14.555404        11.843287   11.650528   19.674500    11.992319\n",
       "\n",
       "[3132 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from data_analysis.data_analysis_utils import *\n",
    "from VennCalibration.quantile_regression import *\n",
    "from VennCalibration.venn_multicalibration import *\n",
    "from VennCalibration.basis_transform import *\n",
    "\n",
    "\n",
    " \n",
    "base_path = \"data_analysis/datasets/\"\n",
    "data_name = \"meps_21\"\n",
    "random_state = 32\n",
    "p_train = 0.5\n",
    "p_cal = 0.3\n",
    "log_transform_y = False\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "X_train, y_train, X_cal, y_cal, X_test, y_test = prepare_data(data_name, \n",
    "                                                                  base_path,\n",
    "        random_state=random_state,\n",
    "        p_train=p_train, p_cal=p_cal,\n",
    "        log_transform_y=log_transform_y)\n",
    "\n",
    "\n",
    "# compute median predictor as poorly calibrated mean predictor\n",
    "predictor = quantile_regression(X_train, y_train, alpha = 0.5, test_size = 0.2)\n",
    "basis_transform = generate_spline_basis_transform(X_cal, n_splines = 5)\n",
    "\n",
    "\n",
    "\n",
    "output = venn_multicalibration(predictor, X_cal, y_cal, X_test, basis_transform, y_test = y_test)\n",
    "\n",
    "output\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b006fe22-30af-4f4b-abc7-92ccf6f73528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "n = 300\n",
    "# Generate feature values\n",
    "X = np.sort(np.concatenate([\n",
    "    np.linspace(0, 10, 150),  # Dense regular points\n",
    "    np.random.uniform(0, 10, n)  # Additional random points for variability\n",
    "]))\n",
    "\n",
    "# Generate response values with some added noise\n",
    "y = np.sin(X) + np.random.normal(scale=0.5, size=len(X))\n",
    " \n",
    "# Split into training and calibration data\n",
    "X_train, X_cal, y_train, y_cal = train_test_split(X, y, y_redraw, test_size=0.3, random_state=42)\n",
    "\n",
    "X_test = X\n",
    "y_test = np.sin(X) + np.random.normal(scale=0.5, size=len(X))\n",
    "\n",
    "# Fit a Generalized Additive Model (GAM) to the training data\n",
    "gam = GAM(s(0, n_splines=10)).fit(X_train.reshape(-1, 1), y_train)\n",
    "\n",
    "\n",
    "    \n",
    "# Generate basis transform\n",
    "basis_transform = generate_spline_basis_transform(X_cal, n_splines=10)\n",
    "    \n",
    "# Perform Venn multicalibration\n",
    "output = venn_multicalibration(predictor, X_cal, y_cal, X_test, basis_transform, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bcd4b1d5-9d08-4132-a890-741170fafae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7,)\n",
      "Calibration Errors:\n",
      "[4.35400000e+03 1.80000000e+01 9.91097237e-02 2.29201982e+00\n",
      " 1.74745101e-03 3.68142362e-02 1.38161573e-03]\n",
      "(7,)\n",
      "(7,)\n",
      "(7,)\n",
      "(7,)\n",
      "(7,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larsvanderlaan/repos/VennCalibration/data_analysis/datasets/datasets.py:335: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  attrib = pd.read_csv(base_path + 'communities_attributes.csv', delim_whitespace = True)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along axis 1; size of axis is 966 but size of corresponding boolean axis is 798",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 127\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28mprint\u001b[39m(calibration_errors)\n\u001b[1;32m    125\u001b[0m base_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_analysis/datasets/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 127\u001b[0m results \u001b[38;5;241m=\u001b[39m [\u001b[43mrun_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_transform_y\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmeps_21\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m data_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbike\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbio\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstar\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeps_21\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconcrete\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcommunity\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "Cell \u001b[0;32mIn[27], line 96\u001b[0m, in \u001b[0;36mrun_dataset\u001b[0;34m(data_name, base_path, num_reps, p_train, p_cal, log_transform_y)\u001b[0m\n\u001b[1;32m     94\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(seed)\n\u001b[1;32m     95\u001b[0m random_states \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1e6\u001b[39m, size\u001b[38;5;241m=\u001b[39mnum_reps)\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m---> 96\u001b[0m output_list \u001b[38;5;241m=\u001b[39m [\u001b[43mreport_calibration_errors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_cal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_transform_y\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m \n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m state \u001b[38;5;129;01min\u001b[39;00m random_states]\n\u001b[1;32m     98\u001b[0m output \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack([output_list])\n\u001b[1;32m     99\u001b[0m metrics \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(output, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[27], line 50\u001b[0m, in \u001b[0;36mreport_calibration_errors\u001b[0;34m(data_name, base_path, random_state, p_train, p_cal, log_transform_y)\u001b[0m\n\u001b[1;32m     47\u001b[0m predictor \u001b[38;5;241m=\u001b[39m quantile_regression(X_train, y_train, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Generate basis transform\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m basis_transform \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_spline_basis_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_cal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Perform Venn multicalibration\u001b[39;00m\n\u001b[1;32m     53\u001b[0m output \u001b[38;5;241m=\u001b[39m venn_multicalibration(predictor, X_cal, y_cal, X_test, basis_transform, y_test\u001b[38;5;241m=\u001b[39my_test)\n",
      "File \u001b[0;32m~/repos/VennCalibration/VennCalibration/basis_transform.py:68\u001b[0m, in \u001b[0;36mgenerate_spline_basis_transform\u001b[0;34m(X, n_splines)\u001b[0m\n\u001b[1;32m     66\u001b[0m tol \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-3\u001b[39m  \u001b[38;5;66;03m# Stricter tolerance\u001b[39;00m\n\u001b[1;32m     67\u001b[0m non_collinear_columns \u001b[38;5;241m=\u001b[39m s \u001b[38;5;241m>\u001b[39m tol\n\u001b[0;32m---> 68\u001b[0m reduced_basis \u001b[38;5;241m=\u001b[39m \u001b[43mfinal_basis\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_collinear_columns\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# Define transformation function\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbasis_transform\u001b[39m(new_X):\n",
      "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along axis 1; size of axis is 966 but size of corresponding boolean axis is 798"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from data_analysis.datasets.datasets import *\n",
    "from data_analysis.data_analysis_utils import *\n",
    "\n",
    "\n",
    "from VennCalibration.quantile_regression import quantile_regression\n",
    "from VennCalibration.basis_transform import generate_spline_basis_transform\n",
    "from VennCalibration.venn_multicalibration import venn_multicalibration\n",
    "\n",
    "def report_calibration_errors(data_name, base_path, random_state=32, p_train=0.5, p_cal=0.3, log_transform_y=False):\n",
    "    \"\"\"\n",
    "    Compute and report calibration errors for a given dataset.\n",
    "\n",
    "    Parameters:\n",
    "        data_name (str): Name of the dataset.\n",
    "        base_path (str): Path to the datasets.\n",
    "        random_state (int): Random seed for reproducibility.\n",
    "        p_train (float): Proportion of data used for training.\n",
    "        p_cal (float): Proportion of data used for calibration.\n",
    "        log_transform_y (bool): Whether to apply log transformation to the response variable.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Calibration errors for each prediction type.\n",
    "    \"\"\"\n",
    "    # Prepare data\n",
    "    X_train, y_train, X_cal, y_cal, X_test, y_test = prepare_data(\n",
    "        data_name,\n",
    "        base_path,\n",
    "        random_state=random_state,\n",
    "        p_train=p_train,\n",
    "        p_cal=p_cal,\n",
    "        log_transform_y=log_transform_y\n",
    "    )\n",
    "\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    # Initialize the MinMaxScaler\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    # Scale to [0,1]\n",
    "    y_train = scaler.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
    "    y_cal = scaler.transform(y_cal.reshape(-1, 1)).flatten()\n",
    "    y_test = scaler.transform(y_test.reshape(-1, 1)).flatten()\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "    # Compute median predictor as poorly calibrated mean predictor\n",
    "    predictor = quantile_regression(X_train, y_train, alpha=0.5, test_size=0.2)\n",
    "    \n",
    "    # Generate basis transform\n",
    "    basis_transform = generate_spline_basis_transform(X_cal, n_splines=10)\n",
    "    \n",
    "    # Perform Venn multicalibration\n",
    "    output = venn_multicalibration(predictor, X_cal, y_cal, X_test, basis_transform, y_test=y_test)\n",
    "\n",
    "    # Extract predictions from the output\n",
    "    mu_lower = output['pred_lower'].to_numpy()\n",
    "    mu_upper = output['pred_upper'].to_numpy()\n",
    "    mu_cal = output['pred_calibrated'].to_numpy()\n",
    "    mu = output['pred_original'].to_numpy()\n",
    "    mu_oracle = output['pred_oracle'].to_numpy()\n",
    "\n",
    "    # Transform the basis functions\n",
    "    basis = basis_transform(X_test).T  # Transpose for iteration over basis functions\n",
    "\n",
    "    # Normalize and center each basis function\n",
    "\n",
    "    basis_normalized = [\n",
    "        b  if np.array_equal(np.unique(b), [0, 1])  # Check if b is binary (only 0s and 1s)\n",
    "        else (b - np.mean(b)) / np.std(b) if np.std(b) > 0  # Normalize if standard deviation > 0\n",
    "        else 1 + 0 * b  # Handle the case where std(b) == 0\n",
    "        for b in basis\n",
    "    ]\n",
    "\n",
    "\n",
    "    # Calculate the basis-transformed projections\n",
    "    results = np.array([\n",
    "        [np.mean(b * (y_test - mu)),\n",
    "         np.mean(b * (y_test - mu_cal)),\n",
    "         np.mean(b * (y_test - mu_oracle))]\n",
    "        for b in basis_normalized\n",
    "    ])\n",
    "\n",
    "    # Compute calibration errors for each column of `results`\n",
    "    cal_errors = np.array([np.sqrt(np.mean(scores**2)) for scores in results.T])\n",
    "    average_width = np.mean(np.abs(mu_upper - mu_lower))\n",
    "    average_rel_width = np.mean(np.abs(mu_upper - mu_lower) / (0.01 + np.abs(mu_oracle)))\n",
    "    IQR = np.abs(np.quantile(y_cal, 0.75) - np.quantile(y_cal, 0.25))\n",
    "    dims = X_train.shape\n",
    "    out = np.concatenate([[dims[0], dims[1], average_width, average_rel_width], cal_errors])\n",
    "    return out\n",
    "\n",
    "def run_dataset(data_name, base_path, num_reps=100, p_train=0.4, p_cal=0.4, log_transform_y=False):\n",
    "    seed = 42\n",
    "    np.random.seed(seed)\n",
    "    random_states = np.random.randint(0, 1e6, size=num_reps).tolist()\n",
    "    output_list = [report_calibration_errors(data_name, base_path, random_state=state, p_train=0.4, p_cal=0.4, log_transform_y=False) \n",
    "    for state in random_states]\n",
    "    output = np.hstack([output_list])\n",
    "    metrics = np.mean(output, axis = 0)\n",
    "    print(metrics.shape)\n",
    "    return metrics\n",
    "\n",
    "\n",
    "# Parameters for the dataset\n",
    "data_name = \"bike\"\n",
    "base_path = \"data_analysis/datasets/\"\n",
    "\n",
    "\n",
    "# Report calibration errors\n",
    "calibration_errors = run_dataset(\n",
    "    data_name=data_name,\n",
    "    base_path=base_path,\n",
    "    num_reps = 3,\n",
    "    p_train=0.4,\n",
    "    p_cal=0.4,\n",
    "    log_transform_y=False\n",
    ")\n",
    "\n",
    "print(\"Calibration Errors:\")\n",
    "print(calibration_errors)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "base_path = \"data_analysis/datasets/\"\n",
    "\n",
    "results = [run_dataset(data_name, base_path = base_path, log_transform_y = (data_name == \"meps_21\")) for data_name in ['bike', 'bio', 'star', 'meps_21', 'concrete', 'community']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "550d5e4b-4c95-46a1-85de-57304e31abeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.35400000e+03, 1.80000000e+01, 8.60835181e-03, 1.40815659e-01,\n",
       "        1.92771848e-03, 1.54358396e-03, 1.51061419e-03],\n",
       "       [1.82920000e+04, 9.00000000e+00, 1.01994444e-02, 5.87785817e-02,\n",
       "        7.32763242e-03, 1.00067820e-02, 9.44897369e-03],\n",
       "       [8.64000000e+02, 3.90000000e+01, 3.26294000e-01, 9.07183352e-01,\n",
       "        9.83800221e-03, 1.13073099e-02, 7.81692218e-03],\n",
       "       [6.26200000e+03, 1.39000000e+02, 8.79446188e-03, 4.48441223e-01,\n",
       "        3.17261017e-03, 1.67217742e-03, 1.61867281e-03],\n",
       "       [4.12000000e+02, 8.00000000e+00, 1.42989492e-01, 5.76762721e-01,\n",
       "        7.67783504e-03, 8.09220103e-03, 6.41738216e-03],\n",
       "       [7.97000000e+02, 1.01000000e+02, 6.65474022e-01, 7.49947255e+00,\n",
       "        9.89853608e-03, 2.08707233e-02, 5.48287698e-03]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26523d9a-a9e4-4d3d-bbac-4a05841893d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parameters for the dataset\n",
    "data_name = \"meps_21\"\n",
    "base_path = \"data_analysis/datasets/\"\n",
    "\n",
    "\n",
    "# Report calibration errors\n",
    "calibration_errors = run_dataset(\n",
    "    data_name=data_name,\n",
    "    base_path=base_path,\n",
    "    num_reps = 3,\n",
    "    p_train=0.5,\n",
    "    p_cal=0.3,\n",
    "    log_transform_y=False\n",
    ")\n",
    "\n",
    "print(\"Calibration Errors:\")\n",
    "print(calibration_errors)\n",
    "\n",
    "\n",
    "\n",
    "# Original design matrix (X) and response vector (y)\n",
    "X = X_basis#[:, 20:30]  # Exclude intercept column if present\n",
    "y = y.reshape(-1, 1)  # Ensure y is a column vector\n",
    "XTX = X.T @ X + lambda_reg * np.eye(X.shape[1])  # Add ridge penalty\n",
    "XTy = X.T @ y \n",
    "XTX_inv = np.linalg.inv(XTX)\n",
    "\n",
    "# New observation (row) to add to the design matrix\n",
    "x_new = X[1]  # New row of X (1 x p)\n",
    "y_new = y[1]  # Corresponding new response value (scalar)\n",
    "lambda_reg = 1e-3\n",
    "beta_updated = compute_updated_solution(XTX_inv, XTy, x_new, y_new, lambda_reg, verify=True)\n",
    "\n",
    "\n",
    "# Verification: beta from the new design matrix\n",
    "x_new = np.array(x_new).reshape(1, -1)\n",
    "if isinstance(y_new, (np.ndarray, list)):\n",
    "    y_new = np.array(y_new).flatten()  # Flatten to 1D\n",
    "    if y_new.size != 1:\n",
    "        raise ValueError(\"y_new must be a scalar or a single-element array.\")\n",
    "    y_new = float(y_new[0])\n",
    "else:\n",
    "    y_new = float(y_new)\n",
    "X_new = np.vstack([X, x_new])  # Updated design matrix\n",
    "y_new_vec = np.vstack([y, [[y_new]]])  # Updated response vector\n",
    "XTX_new = X_new.T @ X_new + lambda_reg * np.eye(X_new.shape[1])  # Apply ridge penalty\n",
    "beta_new = np.linalg.inv(XTX_new) @ (X_new.T @ y_new_vec)\n",
    "# Print the difference and verify\n",
    "print(\"Difference between updated and recomputed beta:\", np.mean(np.abs(beta_updated - beta_new)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3d42e0-b7e6-4b98-871e-d359e41503fa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a93f89e5-179f-4ee8-849f-b737064c9042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.61733651, 2.27077723, 2.63314652, ..., 3.58470702, 2.25344348,\n",
       "        3.23384404], shape=(5000,)),\n",
       " array([[ 1.60338552,  6.06549911],\n",
       "        [-2.04960446,  5.94476013],\n",
       "        [-0.0970772 ,  6.12253074],\n",
       "        ...,\n",
       "        [ 1.67944427,  5.73864488],\n",
       "        [-1.09333973,  6.22431163],\n",
       "        [ 0.27620818,  6.41545658]], shape=(5000, 2)))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from VennCalibration.VennQuantilePredictor import *\n",
    "from VennCalibration.quantile_regression import *\n",
    "from VennCalibration.CQR import *\n",
    "  \n",
    "predictor_venn = conformal_venn_prediction(X, Y, X, Y, alpha = 0.1)\n",
    "#predictor_cqr = CQR(X, Y, X, Y, alpha=0.1)\n",
    "y_median, intervals = predictor_venn(X) \n",
    "\n",
    "\n",
    "calculate_coverage_in_bins(bin_ids, intervals, outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03f5d6b-44bc-4da5-8966-d2805ffa9533",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265f0e14-eac3-4e9a-88d5-5958d1c07dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "from VennCalibration.quantile_regression import *\n",
    "from VennCalibration.calibrators import *\n",
    "\n",
    "alpha = 0.1\n",
    "quantile_predictor = quantile_regression(X, Y, alpha=1 - alpha)\n",
    "q = quantile_predictor(X)\n",
    "\n",
    "# Apply isotonic calibration\n",
    "transform = quantile_calibrator_isotonic(q, Y, alpha=1 - alpha, max_depth=20, num_boost_round=5)\n",
    "\n",
    "# Sort q for smooth plotting\n",
    "q_sorted_indices = np.argsort(q)\n",
    "q_sorted = q[q_sorted_indices]\n",
    "transform_sorted = transform(q_sorted)\n",
    "\n",
    "# Create a density plot on the x-axis using KDE\n",
    "kde = gaussian_kde(q)\n",
    "q_density = kde(q_sorted)\n",
    "\n",
    "# Create a secondary axis for the density plot\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "# Plot the quantile calibration curve\n",
    "ax1.plot(q_sorted, transform_sorted, label='Calibrated Quantile', color='blue')\n",
    "ax1.set_xlabel('Uncalibrated Quantile Predictions')\n",
    "ax1.set_ylabel('Calibrated Quantile Predictions', color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "ax1.grid(True)\n",
    "\n",
    "# Create a twin axis sharing the same x-axis for density plot\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(q_sorted, q_density, label='Density of q', color='orange', alpha=0.7)\n",
    "ax2.set_ylabel('Density', color='orange')\n",
    "ax2.tick_params(axis='y', labelcolor='orange')\n",
    "\n",
    "fig.suptitle(f'Quantile Calibration Curve with Density Plot (alpha={alpha})')\n",
    "fig.legend(loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7590bc8a-4b5b-4550-b478-9057726e944c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.61733651, 2.27077723, 2.63314652, ..., 3.58470702, 2.25344348,\n",
       "        3.23384404], shape=(5000,)),\n",
       " array([[ 1.60338552,  6.06549911],\n",
       "        [-2.04960446,  5.94476013],\n",
       "        [-0.0970772 ,  6.12253074],\n",
       "        ...,\n",
       "        [ 1.67944427,  5.73864488],\n",
       "        [-1.09333973,  6.22431163],\n",
       "        [ 0.27620818,  6.41545658]], shape=(5000, 2)))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedac9b6-0132-4ee2-a45b-6ccb47a7e25b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv2)",
   "language": "python",
   "name": "myenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
